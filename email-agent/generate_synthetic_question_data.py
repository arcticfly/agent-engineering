from __future__ import annotations

import sqlite3
from typing import Iterator, List, Literal

from local_email_db import DEFAULT_DB_PATH
from project_types import Email, Scenario
from rich import print

# Third-party
import litellm
from litellm import acompletion
from litellm.caching.caching import LiteLLMCacheType, Cache
from pydantic import BaseModel, Field

# Std-lib
import asyncio
import json
import os
from textwrap import dedent


def iterate_inbox_batches(
    email_address: str,
    *,
    batch_size: int = 20,
    db_path: str = DEFAULT_DB_PATH,
) -> Iterator[List[Email]]:
    """Yield batches of ``Email`` objects for the given ``email_address``.

    The function returns an *iterator* where each item is a list (batch) of
    ``Email`` objects whose size is at most ``batch_size``.

    A message belongs to the *inbox* when **either** of the following is true:
    1. ``email_address`` appears in the *recipients* table for that message.
    2. The message was *sent* from ``email_address`` (``from_address`` column).

    Parameters
    ----------
    email_address:
        The e-mail address (case-insensitive) whose messages we want to
        iterate over.
    batch_size:
        Size of the batch to yield on every iteration. Defaults to ``20``.
    db_path:
        Path to the SQLite database. Defaults to the database generated by
        ``local_email_db``.
    """

    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row  # access columns by name

    # Normalise for case-insensitive comparison inside SQLite
    email_address_norm = email_address.lower()

    # First, gather *all* message IDs that belong to this inbox. We keep it
    # simple and rely on SQLite to do the heavy lifting.
    #
    # Using a nested query with DISTINCT ensures every message appears once even
    # when the address is present multiple times (e.g. both TO and CC).
    base_query_ids = """
        SELECT DISTINCT e.id
        FROM emails e
        LEFT JOIN recipients r ON r.email_id = e.id
        WHERE LOWER(e.from_address) = ? OR LOWER(r.recipient_address) = ?
        ORDER BY e.date ASC
        """

    cursor = conn.execute(base_query_ids, (email_address_norm, email_address_norm))
    all_email_ids = [row["id"] for row in cursor.fetchall()]

    total = len(all_email_ids)
    if total == 0:
        conn.close()
        return  # Empty iterator

    # Helper to fetch a batch of Email objects given a slice of ids
    def _fetch_batch(id_slice: List[int]) -> List[Email]:
        placeholders = ",".join(["?"] * len(id_slice))
        emails_query = f"""
            SELECT id, message_id, subject, from_address, date, body, file_name
            FROM emails
            WHERE id IN ({placeholders})
            ORDER BY date ASC
        """
        email_rows = conn.execute(emails_query, id_slice).fetchall()

        batch: List[Email] = []
        for row in email_rows:
            rec_cursor = conn.execute(
                "SELECT recipient_address, recipient_type FROM recipients WHERE email_id = ?",
                (row["id"],),
            )
            to_list, cc_list, bcc_list = [], [], []
            for rec in rec_cursor.fetchall():
                if rec["recipient_type"] == "to":
                    to_list.append(rec["recipient_address"])
                elif rec["recipient_type"] == "cc":
                    cc_list.append(rec["recipient_address"])
                elif rec["recipient_type"] == "bcc":
                    bcc_list.append(rec["recipient_address"])

            email_obj = Email(
                message_id=row["message_id"],
                date=row["date"],
                subject=row["subject"],
                from_address=row["from_address"],
                to_addresses=to_list,
                cc_addresses=cc_list,
                bcc_addresses=bcc_list,
                body=row["body"],
                file_name=row["file_name"],
            )
            batch.append(email_obj)
        return batch

    # Yield batches lazily
    for start in range(0, total, batch_size):
        id_batch = all_email_ids[start : start + batch_size]
        yield _fetch_batch(id_batch)

    conn.close()


# ---------------------------------------------------------------------------
# Synthetic Q&A generation utilities
# ---------------------------------------------------------------------------

# Enable LiteLLM caching on disk (same pattern as rollout.py)
litellm.cache = Cache(type=LiteLLMCacheType.DISK)


class Response(BaseModel):
    questions: List[GeneratedSyntheticQuery]


class GeneratedSyntheticQuery(BaseModel):
    question: str
    answer: str
    message_ids: List[str]
    how_realistic: float = Field(
        ...,
        description="Give a score between 0 and 1 on how realistic this question is. That is, how likely is it that the user would actually ask this question of their inbox?",
    )


def _email_to_prompt_snippet(email: Email, idx: int) -> str:
    """Return a concise, readable snippet for one e-mail to embed in the prompt."""

    body_preview = (email.body or "").strip().replace("\r", " ").replace("\n", " ")
    if len(body_preview) > 500:
        body_preview = body_preview[:500] + " …"

    snippet = dedent(
        f"""
        Email {idx}
        Subject: {email.subject or "N/A"}
        From: {email.from_address or "N/A"}
        Date: {email.date}
        Body: {body_preview}
        Message-ID: {email.message_id}
        """
    ).strip()
    return snippet


async def generate_qa_pairs_for_batch(
    batch: List[Email],
    *,
    num_pairs: int = 8,
    model: str = "openrouter/qwen/qwen3-32b",
) -> List[GeneratedSyntheticQuery]:
    """Ask an LLM to create question–answer pairs for a batch of e-mails."""

    system_prompt = dedent(
        f"""
        You are an assistant that creates realistic question–answer pairs a human might ask about their e-mails.
        Every answer MUST be fully contained in the provided e-mails. Do NOT hallucinate.

        Respond with a JSON object with the following structure:
        {Response.model_json_schema()}
        """
    ).strip()

    # Build a compact representation of the e-mails for the prompt
    email_snippets = "\n---\n".join(
        _email_to_prompt_snippet(email, idx=i + 1) for i, email in enumerate(batch)
    )

    user_prompt = dedent(
        f"""
        Here are {len(batch)} e-mails from a user's inbox:
        ---
        {email_snippets}
        ---

        Generate {num_pairs} diverse question–answer pairs.
        """
    ).strip()

    resp = await acompletion(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        caching=True,
        stream=False,
        response_format=Response,
    )

    content = resp["choices"][0]["message"]["content"]  # type: ignore
    qa_pairs = Response.model_validate_json(content).questions

    return qa_pairs


dataset_entry_id = 0


async def generate_dataset_for_inbox(
    inbox_address: str,
    split: Literal["train", "test"],
    *,
    output_path: str = "synthetic_qa_dataset.jsonl",
    max_batches: int | None = None,
    batch_size: int = 20,
    model: str = "openrouter/qwen/qwen3-32b",
) -> None:
    """Iterate over an inbox and save synthetic QA pairs to *output_path* (JSON-Lines)."""
    global dataset_entry_id

    # Ensure directory exists
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)

    batch_iter = iterate_inbox_batches(inbox_address, batch_size=batch_size)

    total_written = 0
    with open(output_path, "a", encoding="utf-8") as f:
        for batch_idx, batch in enumerate(batch_iter):
            batch_last_date = batch[-1].date

            if max_batches is not None and batch_idx >= max_batches:
                break

            print(
                f"[blue]Processing batch {batch_idx + 1} (size={len(batch)}) for {inbox_address}…[/blue]"
            )

            qa_pairs = await generate_qa_pairs_for_batch(batch, model=model)
            for qa in qa_pairs:
                f.write(
                    Scenario(
                        id=dataset_entry_id,
                        question=qa.question,
                        answer=qa.answer,
                        message_ids=qa.message_ids,
                        how_realistic=qa.how_realistic,
                        inbox_address=inbox_address,
                        query_date=batch_last_date,
                        split=split,
                    ).model_dump_json()
                    + "\n"
                )
                dataset_entry_id += 1
                total_written += 1

    print(f"[green]Finished. Wrote {total_written} QA pairs to {output_path}.[/green]")


# ---------------------------------------------------------------------------
# CLI entry-point – generate synthetic dataset for a random inbox
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    import argparse
    from train_and_test_inboxes import get_inbox

    parser = argparse.ArgumentParser(
        description="Generate synthetic Q&A data from e-mails."
    )
    parser.add_argument("--split", choices=["train", "test"], default="train")
    parser.add_argument(
        "--output",
        default="data/synthetic_qa_dataset.jsonl",
        help="Path to JSONL file.",
    )
    parser.add_argument(
        "--max-batches", type=int, default=None, help="Limit number of batches (debug)."
    )
    parser.add_argument("--batch-size", type=int, default=20)
    args = parser.parse_args()

    inbox_addr = get_inbox(args.split)
    print(f"[bold]Generating synthetic Q&A for inbox:[/bold] {inbox_addr}\n")

    asyncio.run(
        generate_dataset_for_inbox(
            inbox_addr,
            split=args.split,
            output_path=args.output,
            max_batches=args.max_batches,
            batch_size=args.batch_size,
        )
    )
