{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this email search agent, click _Runtime_ and press _Run all_. Make sure you've enabled a free Tesla T4 GPU!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n",
    "\n",
    "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
    "\n",
    "**Email Search Agent**\n",
    "\n",
    "This notebook shows how to train a Qwen 2.5 7B model to search through emails and answer questions about them. The agent will learn to use email search tools effectively to find relevant information.\n",
    "\n",
    "You will learn how to construct an [agentic environment](#Environment), how to define a [rollout](#Rollout), and how to run a [training loop](#Loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"numpy<2.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING:\n",
    "\n",
    "If you are running in Google Colab and installing numpy does not say \"Requirement already satisfied: numpy<2.0.0\" then click \"Runtime\" and \"Restart Session.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we're using numpy 1.*.*\n",
    "import numpy as np\n",
    "\n",
    "if (np.__version__).startswith(\"1.\"):\n",
    "    print(\"Numpy version is 1.*.*, you're good to go!\")\n",
    "else:\n",
    "    raise ValueError(\"Please restart your runtime using the above instructions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Environment-Variables\"></a>\n",
    "### Environment Variables\n",
    "\n",
    "**OpenAI (required for RULER)**\n",
    "\n",
    "OpenAI provides a unified API for multiple LLM providers. Our RULER judge model requires it in order to query third-party models to judge the quality of the agent's performance.\n",
    "\n",
    "**Weights & Biases (optional)**\n",
    "\n",
    "Later on in the notebook, we'll be creating a model that can automatically logs metrics to Weights & Biases and chat completions to Weave. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Required\n",
    "OPENAI_API_KEY = \"\"\n",
    "if OPENAI_API_KEY:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY is required for RULER functionality when using openai/o3.\"\n",
    "    )\n",
    "\n",
    "# Optional\n",
    "WANDB_API_KEY = \"\"\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "else:\n",
    "    print(\"WANDB_API_KEY is not set. We'll skip logging metrics to Weights & Biases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install openpipe-art==0.3.11.post2 --prerelease allow --no-cache-dir\n",
    "!uv pip install pydantic langchain-core tenacity litellm weave datasets tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Environment\"></a>\n",
    "\n",
    "### Email Search Environment\n",
    "\n",
    "ART allows your agent to learn by interacting with its environment. In this example, we'll create an environment where the agent can search through emails and answer questions about them.\n",
    "\n",
    "The agent will have access to three tools:\n",
    "1. `search_inbox` - Search for emails by keywords\n",
    "2. `read_email` - Read a specific email by message ID\n",
    "3. `return_final_answer` - Return the final answer with source email IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "from typing import List, Optional, Literal\n",
    "from dataclasses import dataclass, asdict\n",
    "from pydantic import BaseModel, Field\n",
    "from textwrap import dedent\n",
    "from datasets import load_dataset, Dataset, Features, Value, Sequence\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Email and Scenario data models\n",
    "class Email(BaseModel):\n",
    "    message_id: str\n",
    "    date: str  # ISO 8601 string 'YYYY-MM-DD HH:MM:SS'\n",
    "    subject: Optional[str] = None\n",
    "    from_address: Optional[str] = None\n",
    "    to_addresses: List[str] = []  # Populated from recipients table\n",
    "    cc_addresses: List[str] = []  # Populated from recipients table\n",
    "    bcc_addresses: List[str] = []  # Populated from recipients table\n",
    "    body: Optional[str] = None\n",
    "    file_name: Optional[str] = None\n",
    "\n",
    "\n",
    "class Scenario(BaseModel):\n",
    "    id: int\n",
    "    question: str\n",
    "    answer: str\n",
    "    message_ids: List[str]  # message_ids (strings) of referenced emails\n",
    "    how_realistic: float\n",
    "    inbox_address: str\n",
    "    query_date: str\n",
    "    split: Literal[\"train\", \"test\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    message_id: str\n",
    "    snippet: str\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "# Database configuration\n",
    "DB_PATH = \"./enron_emails.db\"\n",
    "EMAIL_DATASET_REPO_ID = \"corbt/enron-emails\"\n",
    "SCENARIO_DATASET_REPO_ID = \"corbt/enron_emails_sample_questions\"\n",
    "\n",
    "# Global database connection\n",
    "db_conn = None\n",
    "\n",
    "\n",
    "def create_email_database():\n",
    "    \"\"\"Create the email database from Hugging Face dataset\"\"\"\n",
    "    print(\"Creating email database from Hugging Face dataset...\")\n",
    "    \n",
    "    # Database schema\n",
    "    SQL_CREATE_TABLES = \"\"\"\n",
    "    DROP TABLE IF EXISTS recipients;\n",
    "    DROP TABLE IF EXISTS emails_fts;\n",
    "    DROP TABLE IF EXISTS emails;\n",
    "\n",
    "    CREATE TABLE emails (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        message_id TEXT UNIQUE,\n",
    "        subject TEXT,\n",
    "        from_address TEXT,\n",
    "        date TEXT,\n",
    "        body TEXT,\n",
    "        file_name TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE recipients (\n",
    "        email_id TEXT,\n",
    "        recipient_address TEXT,\n",
    "        recipient_type TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    SQL_CREATE_INDEXES_TRIGGERS = \"\"\"\n",
    "    CREATE INDEX idx_emails_from ON emails(from_address);\n",
    "    CREATE INDEX idx_emails_date ON emails(date);\n",
    "    CREATE INDEX idx_emails_message_id ON emails(message_id);\n",
    "    CREATE INDEX idx_recipients_address ON recipients(recipient_address);\n",
    "    CREATE INDEX idx_recipients_type ON recipients(recipient_type);\n",
    "    CREATE INDEX idx_recipients_email_id ON recipients(email_id);\n",
    "    CREATE INDEX idx_recipients_address_email ON recipients(recipient_address, email_id);\n",
    "\n",
    "    CREATE VIRTUAL TABLE emails_fts USING fts5(\n",
    "        subject,\n",
    "        body,\n",
    "        content='emails',\n",
    "        content_rowid='id'\n",
    "    );\n",
    "\n",
    "    CREATE TRIGGER emails_ai AFTER INSERT ON emails BEGIN\n",
    "        INSERT INTO emails_fts (rowid, subject, body)\n",
    "        VALUES (new.id, new.subject, new.body);\n",
    "    END;\n",
    "\n",
    "    CREATE TRIGGER emails_ad AFTER DELETE ON emails BEGIN\n",
    "        DELETE FROM emails_fts WHERE rowid=old.id;\n",
    "    END;\n",
    "\n",
    "    CREATE TRIGGER emails_au AFTER UPDATE ON emails BEGIN\n",
    "        UPDATE emails_fts SET subject=new.subject, body=new.body WHERE rowid=old.id;\n",
    "    END;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create database\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executescript(SQL_CREATE_TABLES)\n",
    "    conn.commit()\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"Loading email dataset...\")\n",
    "    expected_features = Features({\n",
    "        \"message_id\": Value(\"string\"),\n",
    "        \"subject\": Value(\"string\"),\n",
    "        \"from\": Value(\"string\"),\n",
    "        \"to\": Sequence(Value(\"string\")),\n",
    "        \"cc\": Sequence(Value(\"string\")),\n",
    "        \"bcc\": Sequence(Value(\"string\")),\n",
    "        \"date\": Value(\"timestamp[us]\"),\n",
    "        \"body\": Value(\"string\"),\n",
    "        \"file_name\": Value(\"string\"),\n",
    "    })\n",
    "    \n",
    "    dataset = load_dataset(EMAIL_DATASET_REPO_ID, features=expected_features, split=\"train\")\n",
    "    \n",
    "    # Populate database (limit to first 1000 emails for demo)\n",
    "    print(\"Populating database...\")\n",
    "    conn.execute(\"PRAGMA synchronous = OFF;\")\n",
    "    conn.execute(\"PRAGMA journal_mode = MEMORY;\")\n",
    "    conn.execute(\"BEGIN TRANSACTION;\")\n",
    "    \n",
    "    record_count = 0\n",
    "    for i, email_data in enumerate(tqdm(dataset.select(range(min(1000, len(dataset)))), desc=\"Inserting emails\")):\n",
    "        message_id = email_data[\"message_id\"]\n",
    "        subject = email_data[\"subject\"]\n",
    "        from_address = email_data[\"from\"]\n",
    "        date_obj: datetime = email_data[\"date\"]\n",
    "        body = email_data[\"body\"]\n",
    "        file_name = email_data[\"file_name\"]\n",
    "        to_list = [str(addr) for addr in email_data[\"to\"] if addr]\n",
    "        cc_list = [str(addr) for addr in email_data[\"cc\"] if addr]\n",
    "        bcc_list = [str(addr) for addr in email_data[\"bcc\"] if addr]\n",
    "        \n",
    "        # Filter out very long emails and those with too many recipients\n",
    "        if len(body) > 5000 or (len(to_list) + len(cc_list) + len(bcc_list)) > 30:\n",
    "            continue\n",
    "            \n",
    "        date_str = date_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO emails (message_id, subject, from_address, date, body, file_name)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (message_id, subject, from_address, date_str, body, file_name))\n",
    "        \n",
    "        email_pk_id = cursor.lastrowid\n",
    "        \n",
    "        # Insert recipients\n",
    "        recipient_data = []\n",
    "        for addr in to_list:\n",
    "            recipient_data.append((message_id, addr, \"to\"))\n",
    "        for addr in cc_list:\n",
    "            recipient_data.append((message_id, addr, \"cc\"))\n",
    "        for addr in bcc_list:\n",
    "            recipient_data.append((message_id, addr, \"bcc\"))\n",
    "            \n",
    "        if recipient_data:\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO recipients (email_id, recipient_address, recipient_type)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", recipient_data)\n",
    "            \n",
    "        record_count += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    # Create indexes and triggers\n",
    "    print(\"Creating indexes and FTS...\")\n",
    "    cursor.executescript(SQL_CREATE_INDEXES_TRIGGERS)\n",
    "    cursor.execute('INSERT INTO emails_fts(emails_fts) VALUES(\"rebuild\")')\n",
    "    conn.commit()\n",
    "    \n",
    "    print(f\"Successfully created database with {record_count} emails.\")\n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Get database connection\"\"\"\n",
    "    global db_conn\n",
    "    if db_conn is None:\n",
    "        if os.path.exists(DB_PATH):\n",
    "            db_conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
    "        else:\n",
    "            db_conn = create_email_database()\n",
    "    return db_conn\n",
    "\n",
    "\n",
    "def search_emails(\n",
    "    inbox: str,\n",
    "    keywords: List[str],\n",
    "    from_addr: Optional[str] = None,\n",
    "    to_addr: Optional[str] = None,\n",
    "    sent_after: Optional[str] = None,\n",
    "    sent_before: Optional[str] = None,\n",
    "    max_results: int = 10,\n",
    ") -> List[SearchResult]:\n",
    "    \"\"\"Search the email database based on keywords and filters\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    where_clauses: List[str] = []\n",
    "    params: List[str | int] = []\n",
    "    \n",
    "    if not keywords:\n",
    "        raise ValueError(\"No keywords provided for search.\")\n",
    "        \n",
    "    if max_results > 10:\n",
    "        raise ValueError(\"max_results must be less than or equal to 10.\")\n",
    "    \n",
    "    # FTS query\n",
    "    fts_query = \" \".join(f'\"{k.replace('\"', '\"\"')}\"' for k in keywords)\n",
    "    where_clauses.append(\"fts.emails_fts MATCH ?\")\n",
    "    params.append(fts_query)\n",
    "    \n",
    "    # Inbox filter\n",
    "    where_clauses.append(\"\"\"\n",
    "        (e.from_address = ? OR EXISTS (\n",
    "            SELECT 1 FROM recipients r_inbox\n",
    "            WHERE r_inbox.recipient_address = ? AND r_inbox.email_id = e.message_id\n",
    "        ))\n",
    "    \"\"\")\n",
    "    params.extend([inbox, inbox])\n",
    "    \n",
    "    if from_addr:\n",
    "        where_clauses.append(\"e.from_address = ?\")\n",
    "        params.append(from_addr)\n",
    "        \n",
    "    if to_addr:\n",
    "        where_clauses.append(\"\"\"\n",
    "            EXISTS (\n",
    "                SELECT 1 FROM recipients r_to\n",
    "                WHERE r_to.recipient_address = ? AND r_to.email_id = e.message_id\n",
    "            )\n",
    "        \"\"\")\n",
    "        params.append(to_addr)\n",
    "        \n",
    "    if sent_after:\n",
    "        where_clauses.append(\"e.date >= ?\")\n",
    "        params.append(f\"{sent_after} 00:00:00\")\n",
    "        \n",
    "    if sent_before:\n",
    "        where_clauses.append(\"e.date < ?\")\n",
    "        params.append(f\"{sent_before} 00:00:00\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            e.message_id,\n",
    "            snippet(emails_fts, -1, '<b>', '</b>', ' ... ', 15) as snippet\n",
    "        FROM\n",
    "            emails e JOIN emails_fts fts ON e.id = fts.rowid\n",
    "        WHERE\n",
    "            {\" AND \".join(where_clauses)}\n",
    "        ORDER BY\n",
    "            e.date DESC\n",
    "        LIMIT ?;\n",
    "    \"\"\"\n",
    "    params.append(max_results)\n",
    "    \n",
    "    cursor.execute(sql, params)\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    return [SearchResult(message_id=row[0], snippet=row[1]) for row in results]\n",
    "\n",
    "\n",
    "def read_email(message_id: str) -> Optional[Email]:\n",
    "    \"\"\"Retrieve a single email by its message_id\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get email details\n",
    "    cursor.execute(\n",
    "        \"SELECT message_id, date, subject, from_address, body, file_name FROM emails WHERE message_id = ?\",\n",
    "        (message_id,)\n",
    "    )\n",
    "    email_row = cursor.fetchone()\n",
    "    \n",
    "    if not email_row:\n",
    "        return None\n",
    "    \n",
    "    msg_id, date, subject, from_addr, body, file_name = email_row\n",
    "    \n",
    "    # Get recipients\n",
    "    cursor.execute(\n",
    "        \"SELECT recipient_address, recipient_type FROM recipients WHERE email_id = ?\",\n",
    "        (message_id,)\n",
    "    )\n",
    "    recipient_rows = cursor.fetchall()\n",
    "    \n",
    "    to_addresses = []\n",
    "    cc_addresses = []\n",
    "    bcc_addresses = []\n",
    "    \n",
    "    for addr, type_val in recipient_rows:\n",
    "        if type_val.lower() == \"to\":\n",
    "            to_addresses.append(addr)\n",
    "        elif type_val.lower() == \"cc\":\n",
    "            cc_addresses.append(addr)\n",
    "        elif type_val.lower() == \"bcc\":\n",
    "            bcc_addresses.append(addr)\n",
    "    \n",
    "    return Email(\n",
    "        message_id=msg_id,\n",
    "        date=date,\n",
    "        subject=subject,\n",
    "        from_address=from_addr,\n",
    "        to_addresses=to_addresses,\n",
    "        cc_addresses=cc_addresses,\n",
    "        bcc_addresses=bcc_addresses,\n",
    "        body=body,\n",
    "        file_name=file_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_training_scenarios(\n",
    "    split: Literal[\"train\", \"test\"] = \"train\",\n",
    "    limit: Optional[int] = None,\n",
    "    max_messages: Optional[int] = 1,\n",
    "    shuffle: bool = False,\n",
    "    seed: Optional[int] = None,\n",
    ") -> List[Scenario]:\n",
    "    \"\"\"Load training scenarios from Hugging Face dataset\"\"\"\n",
    "    print(f\"Loading {split} scenarios from Hugging Face...\")\n",
    "    dataset: Dataset = load_dataset(SCENARIO_DATASET_REPO_ID, split=split)\n",
    "    \n",
    "    if max_messages is not None:\n",
    "        dataset = dataset.filter(lambda x: len(x[\"message_ids\"]) <= max_messages)\n",
    "    \n",
    "    if shuffle or (seed is not None):\n",
    "        if seed is not None:\n",
    "            dataset = dataset.shuffle(seed=seed)\n",
    "        else:\n",
    "            dataset = dataset.shuffle()\n",
    "    \n",
    "    # Convert each row to a Scenario object\n",
    "    scenarios = [Scenario(**row, split=split) for row in dataset]\n",
    "    \n",
    "    if max_messages is not None:\n",
    "        scenarios = [s for s in scenarios if len(s.message_ids) <= max_messages]\n",
    "    \n",
    "    if shuffle:\n",
    "        if seed is not None:\n",
    "            rng = random.Random(seed)\n",
    "            rng.shuffle(scenarios)\n",
    "        else:\n",
    "            random.shuffle(scenarios)\n",
    "    \n",
    "    if limit is not None:\n",
    "        scenarios = scenarios[:limit]\n",
    "    \n",
    "    print(f\"Loaded {len(scenarios)} scenarios.\")\n",
    "    return scenarios\n",
    "\n",
    "\n",
    "# Load training scenarios\n",
    "training_scenarios = load_training_scenarios(split=\"train\", limit=50, max_messages=1, shuffle=True, seed=42)\n",
    "\n",
    "print(\"Email search environment created with real Enron dataset!\")\n",
    "print(f\"Database contains real emails, loaded {len(training_scenarios)} training scenarios.\")\n",
    "\n",
    "# print first two scenarios\n",
    "print(training_scenarios[0])\n",
    "print(training_scenarios[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "Now that we've defined the rules of our environment, we can create a model that will learn to search emails effectively. We'll use a Qwen 2.5 7B model for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "from art.local import LocalBackend\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model\n",
    "model = art.TrainableModel(\n",
    "    name=\"email-agent-001\",\n",
    "    project=\"email-search-agent\",\n",
    "    base_model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    ")\n",
    "\n",
    "# To run on a T4, we need to override some config defaults.\n",
    "model._internal_config = art.dev.InternalModelConfig(\n",
    "    init_args=art.dev.InitArgs(\n",
    "        max_seq_length=8192,\n",
    "    ),\n",
    "    engine_args=art.dev.EngineArgs(\n",
    "        enforce_eager=True,\n",
    "        gpu_memory_utilization=0.8,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "backend = LocalBackend(\n",
    "    # Normally we don't want to run the server in-process, but for the output\n",
    "    # to show up properly on Google Colab we'll enable this.\n",
    "    in_process=True,\n",
    "    path=\"./.art\",\n",
    ")\n",
    "\n",
    "# Register the model with the local Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Rollout\"></a>\n",
    "\n",
    "### Defining a Rollout\n",
    "\n",
    "A rollout is a single episode of an agent performing its task. In this example, the rollout function presents the agent with an email search scenario, and the agent uses the available tools to search for emails and answer the question.\n",
    "\n",
    "When the agent provides a final answer, the `correct` metric is calculated based on whether the answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "import weave\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from tenacity import retry, stop_after_attempt\n",
    "from litellm import acompletion\n",
    "from art.utils.litellm import convert_litellm_choice_to_openai\n",
    "\n",
    "if os.getenv(\"WANDB_API_KEY\", \"\"):\n",
    "    weave.init(model.project, settings={\"print_call_link\": False})\n",
    "\n",
    "MAX_TURNS = 10\n",
    "\n",
    "\n",
    "class CorrectnessJudgeResponse(BaseModel):\n",
    "    reasoning: str = Field(description=\"Explanation of the reasoning process.\")\n",
    "    accept: bool = Field(description=\"Whether the AI answer should be accepted.\")\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(3))\n",
    "async def judge_correctness(scenario: Scenario, answer: str) -> CorrectnessJudgeResponse:\n",
    "    system_prompt = dedent(\n",
    "        \"\"\"\n",
    "        You are given a question, the reference answer (labelled **Reference answer**), and an answer generated by an AI assistant (labelled **AI answer**).\n",
    "\n",
    "        Your task is to decide whether the AI answer is correct and should be accepted. You should accept the answer if it contains the relevant information from the reference answer. You should not accept the answer if it is missing information relevant to the question, or if it contradicts the reference answer.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Question: {scenario.question}\\n\"\n",
    "                f\"Reference answer: {scenario.answer}\\n\"\n",
    "                f\"AI answer: {answer}\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = await acompletion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        response_format=CorrectnessJudgeResponse,\n",
    "    )\n",
    "\n",
    "    first_choice = response.choices[0]\n",
    "    raw_content = first_choice.message.content or \"{}\"\n",
    "\n",
    "    try:\n",
    "        return CorrectnessJudgeResponse.model_validate_json(raw_content)\n",
    "    except Exception as e:\n",
    "        return CorrectnessJudgeResponse(\n",
    "            reasoning=f\"Parse error: {e}\\nRaw: {raw_content}\", accept=False\n",
    "        )\n",
    "\n",
    "\n",
    "class ProjectTrajectory(art.Trajectory):\n",
    "    final_answer: FinalAnswer | None = None\n",
    "\n",
    "\n",
    "class EmailScenario(BaseModel):\n",
    "    step: int\n",
    "    scenario: Scenario\n",
    "\n",
    "\n",
    "@weave.op\n",
    "async def rollout(model: art.Model, email_scenario: EmailScenario) -> ProjectTrajectory:\n",
    "    scenario = email_scenario.scenario\n",
    "    \n",
    "    traj = ProjectTrajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\n",
    "            \"scenario_id\": scenario.id,\n",
    "            \"step\": email_scenario.step,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are an email search agent. You are given a user query and a list of tools you can use to search the user's email. Use the tools to search the user's emails and find the answer to the user's query. You may take up to {MAX_TURNS} turns to find the answer, so if your first search doesn't find the answer, you can try with different keywords.\n",
    "\n",
    "        User's email address is {scenario.inbox_address}\n",
    "        Today's date is {scenario.query_date}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    def search_inbox(keywords: list[str]) -> list[dict]:\n",
    "        \"\"\"Search the inbox for emails matching the given keywords and return\n",
    "        a list of dictionaries so the LLM can easily consume them.\"\"\"\n",
    "        results = search_emails(\n",
    "            inbox=scenario.inbox_address,\n",
    "            keywords=keywords,\n",
    "            sent_before=scenario.query_date,\n",
    "        )\n",
    "        return [asdict(result) for result in results]\n",
    "\n",
    "    def return_final_answer(\n",
    "        answer: str, reference_message_ids: list[str]\n",
    "    ) -> FinalAnswer:\n",
    "        \"\"\"Return the final answer and the message IDs of the emails that were used to generate the answer.\"\"\"\n",
    "        return FinalAnswer(answer=answer, source_ids=reference_message_ids)\n",
    "\n",
    "    tools = [search_inbox, read_email, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    if model.trainable:\n",
    "        litellm_model_name = f\"hosted_vllm/{model.name}\"\n",
    "    else:\n",
    "        litellm_model_name = model.name\n",
    "\n",
    "    for turn in range(MAX_TURNS):\n",
    "        response = await acompletion(\n",
    "            model=litellm_model_name,\n",
    "            base_url=model.inference_base_url,\n",
    "            api_key=model.inference_api_key,\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            caching=False,\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(\n",
    "            convert_litellm_choice_to_openai(response.choices[0])\n",
    "        )\n",
    "\n",
    "        if response_message.content or not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name: str = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    tool_to_call = tools_by_name[tool_name]\n",
    "                    result = tool_to_call(**tool_args)\n",
    "                    traj.messages_and_choices.append(\n",
    "                        {\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"name\": tool_name,\n",
    "                            \"content\": str(result),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        traj.final_answer = result\n",
    "                        # Score the trajectory\n",
    "                        if traj.final_answer:\n",
    "                            correctness_judge_response = await judge_correctness(\n",
    "                                scenario, traj.final_answer.answer\n",
    "                            )\n",
    "                            traj.metrics[\"correct\"] = float(correctness_judge_response.accept)\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing tool calls: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How RULER works\n",
    "\n",
    "**RULER** leverages two key insights:\n",
    "\n",
    "1. Relative scoring is easier than absolute scoring: It's easier for an LLM to rank several solutions relative to each other than to score them in isolation\n",
    "2. GRPO only needs relative scores: Since GRPO normalizes scores within each group, only the relative rankings matter, not absolute values\n",
    "\n",
    "The process:\n",
    "\n",
    "1. Generate N trajectories for a given scenario\n",
    "2. Pass all N trajectories to **RULER**\n",
    "3. **RULER** deduplicates common prefixes (e.g., identical system messages)\n",
    "4. An LLM judge scores each trajectory from 0 to 1 based on goal achievement\n",
    "5. These scores are used directly as rewards in GRPO training\n",
    "\n",
    "To learn more about **RULER**, check out the [RULER docs](https://art.openpipe.ai/fundamentals/ruler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "from art.rewards import ruler_score_group\n",
    "\n",
    "# Test RULER with a simple example\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You count numbers using numeric symbols.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Count to 10.\"},\n",
    "]\n",
    "\n",
    "good_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "mediocre_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"one, two, three, four, five, six, seven, eight, nine, ten\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "bad_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"a, b, c, d, e, f, g, h, i, j\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "sample_group = art.TrajectoryGroup(\n",
    "    trajectories=[\n",
    "        good_trajectory,\n",
    "        mediocre_trajectory,\n",
    "        bad_trajectory,\n",
    "    ]\n",
    ")\n",
    "\n",
    "judged_group = await ruler_score_group(sample_group, \"openai/o4-mini\", debug=True)\n",
    "assert judged_group is not None\n",
    "\n",
    "# Display rankings\n",
    "sorted_trajectories = sorted(\n",
    "    judged_group.trajectories, key=lambda t: t.reward, reverse=True\n",
    ")\n",
    "for rank, traj in enumerate(sorted_trajectories, 1):\n",
    "    messages = traj.messages()\n",
    "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
    "    print(f\"  Response: {messages[-1]['content'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Loop\"></a>\n",
    "\n",
    "### Training Loop\n",
    "\n",
    "The training loop is where the magic happens. For each of the 10 steps defined below, the rollout function will be called multiple times in parallel. Each scenario will produce a trajectory, which will be used to update the model.\n",
    "\n",
    "The `gather` step will wait for all of the trajectories to be generated, then it will use RULER to assign relative scores to each trajectory.\n",
    "\n",
    "Our notebook will then delete all but the most recent checkpoint and train the model on the scored trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "from art.utils import iterate_dataset\n",
    "\n",
    "training_config = {\n",
    "    \"groups_per_step\": 2,\n",
    "    \"num_epochs\": 1,\n",
    "    \"rollouts_per_group\": 3,\n",
    "    \"learning_rate\": 1e-5,\n",
    "}\n",
    "\n",
    "GROUP_SIZE = 3\n",
    "\n",
    "# Use iterate_dataset with real training scenarios (similar to train.py)\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,  # Use real scenarios from Hugging Face\n",
    "    groups_per_step=2,\n",
    "    num_epochs=1,\n",
    "    initial_step=await model.get_step(),\n",
    ")\n",
    "\n",
    "for batch, epoch, global_step, epoch_step in training_iterator:\n",
    "    print(f\"Training step {global_step}, epoch {epoch}, epoch step {epoch_step}\")\n",
    "    print(f\"Batch contains {len(batch)} scenarios\")\n",
    "    \n",
    "    # Create trajectory groups for this batch (similar to train.py)\n",
    "    groups = []\n",
    "    for scenario in batch:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, EmailScenario(step=global_step, scenario=scenario))\n",
    "                    for _ in range(GROUP_SIZE)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Gather all trajectory groups\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"gather\",\n",
    "        max_exceptions=GROUP_SIZE * len(batch),\n",
    "    )\n",
    "\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        # Use RULER to assign relative scores to each trajectory\n",
    "        judged_group = await ruler_score_group(group, \"openai/o4-mini\", debug=True)\n",
    "        judged_groups.append(judged_group)\n",
    "\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=1e-5),\n",
    "        # Lowering the logprob_calculation_chunk_size is a memory saving measure\n",
    "        # to allow longer sequences (up to 8192 tokens) to be processed on a T4.\n",
    "        _config={\"logprob_calculation_chunk_size\": 8},\n",
    "    )\n",
    "    \n",
    "    print(f\"Completed training step {global_step}\")\n",
    "    \n",
    "    # Stop after 5 steps for demo purposes (adjust as needed)\n",
    "    if global_step >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "Just like that, you've trained an agent to search emails and answer questions! Now it's time to use your model outside of ART. The easiest way to do that is to load it from disk, where it was saved after each training step.\n",
    "\n",
    "Check out the code below for a small demo of the model you just trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load the trained model\n",
    "lora_model_path = (\n",
    "    f\".art/{model.project}/models/{model.name}/{await model.get_step():04d}\"\n",
    ")\n",
    "\n",
    "print(f\"Loading model from {lora_model_path}\\n\")\n",
    "\n",
    "peft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=lora_model_path,\n",
    "    max_seq_length=16384,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "FastLanguageModel.for_inference(peft_model)\n",
    "\n",
    "# Test the model with a real scenario from the training set\n",
    "test_scenario = training_scenarios[0]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are an email search agent. Use the available tools to search emails and answer questions. User's email address is {test_scenario.inbox_address}. Today's date is {test_scenario.query_date}.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": test_scenario.question},\n",
    "]\n",
    "\n",
    "print(f\"Test scenario ID: {test_scenario.id}\")\n",
    "print(f\"Question: {test_scenario.question}\")\n",
    "print(f\"Expected answer: {test_scenario.answer}\")\n",
    "print(f\"Reference message IDs: {test_scenario.message_ids}\")\n",
    "print(f\"Inbox: {test_scenario.inbox_address}\")\n",
    "print(f\"Query date: {test_scenario.query_date}\")\n",
    "print(\"\\nModel response:\")\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages, return_tensors=\"pt\", add_generation_prompt=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = peft_model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = tokenizer.decode(\n",
    "        outputs[0][inputs.shape[1] :], skip_special_tokens=True\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Email search agent training completed successfully!\")\n",
    "print(\"The model has been trained on real Enron email data and scenarios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/notebooks/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/notebooks/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://openpipe.ai/blog/art-e-mail-agent\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_E_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
